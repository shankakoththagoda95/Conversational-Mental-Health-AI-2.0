{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6bd698",
   "metadata": {},
   "source": [
    "## PHQ-9 Conversations Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eaeb2a",
   "metadata": {},
   "source": [
    "PHQ-9 Queations Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb5405",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_FOLDER = \"Conversations/PHQ9/Question based Conversation/\"        # folder containing all patient JSON files\n",
    "OUTPUT_CSV = \"Analysis/PHQ9/Questionnaire_summary.csv\"     # output summary file\n",
    "# -----------------------------\n",
    "\n",
    "def extract_patient_name(file_path):\n",
    "    \"\"\"Get patient name from JSON or filename.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    # most files have the patient’s name as the first key of \"Common Questions\"\n",
    "    if \"Common Questions\" in data and len(data[\"Common Questions\"]) > 0:\n",
    "        first_item = data[\"Common Questions\"][0]\n",
    "        for k in first_item.keys():\n",
    "            if k.lower() not in (\"consultant\",):\n",
    "                return k.strip()\n",
    "    # fallback to filename\n",
    "    return os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "def extract_ratings(file_path):\n",
    "    \"\"\"Extract 9 PHQ-9 ratings from Ava_Brooks-style JSON.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    ratings = []\n",
    "    if \"Common Questions\" in data:\n",
    "        for item in data[\"Common Questions\"]:\n",
    "            # each question is a dict with 'Consultant' and '<Name>'\n",
    "            for k, v in item.items():\n",
    "                if k.lower() != \"consultant\" and isinstance(v, str):\n",
    "                    # find rating numbers like \"Rating: 2\", \"rated it 3\", \"2—More\"\n",
    "                    match = re.search(r\"\\b([0-3])\\b\", v)\n",
    "                    if match:\n",
    "                        ratings.append(int(match.group(1)))\n",
    "                    else:\n",
    "                        ratings.append(None)\n",
    "    # Ensure exactly 9 ratings\n",
    "    ratings = (ratings + [None]*9)[:9]\n",
    "    return ratings\n",
    "\n",
    "def main():\n",
    "    files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith(\".json\")]\n",
    "    all_rows = []\n",
    "\n",
    "    for idx, file_name in enumerate(files, start=1):\n",
    "        file_path = os.path.join(INPUT_FOLDER, file_name)\n",
    "        name = extract_patient_name(file_path)\n",
    "        ratings = extract_ratings(file_path)\n",
    "        total = sum(r for r in ratings if isinstance(r, int))\n",
    "        row = {\"No.\": idx, \"Name\": name}\n",
    "        for i, r in enumerate(ratings, start=1):\n",
    "            row[f\"Q{i}\"] = r\n",
    "        row[\"Total\"] = total\n",
    "        all_rows.append(row)\n",
    "        print(f\"Processed {name} → Total Score: {total}\")\n",
    "\n",
    "    # Write CSV\n",
    "    fieldnames = [\"No.\", \"Name\"] + [f\"Q{i}\" for i in range(1, 10)] + [\"Total\"]\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_rows)\n",
    "\n",
    "    print(f\"\\n✅ Saved summary to {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087630e",
   "metadata": {},
   "source": [
    "Casual Conversation Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92aa94a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from openai import OpenAI\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_FOLDER = \"Conversations/PHQ9/Normal Conversation/\"\n",
    "OUTPUT_CSV = \"analysis/Normal_estimates.csv\"\n",
    "MODEL_NAME = \"gpt-4o-mini\"   # or \"gpt-4o-mini\"\n",
    "# -----------------------------\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "PHQ9_PROMPT = \"\"\"\n",
    "You are a clinician scoring the PHQ-9 depression questionnaire.\n",
    "Based only on this conversation, estimate the patient's scores for each PHQ-9 item (Q1–Q9),\n",
    "where each item is rated 0–3 (0=Not at all, 1=Several days, 2=More than half the days, 3=Nearly every day).\n",
    "Provide your answer in *strict JSON only* using this exact structure:\n",
    "{\n",
    "  \"Q1\": <int>, \"Q2\": <int>, \"Q3\": <int>, \"Q4\": <int>, \"Q5\": <int>,\n",
    "  \"Q6\": <int>, \"Q7\": <int>, \"Q8\": <int>, \"Q9\": <int>, \"Total\": <int>\n",
    "}\n",
    "Do not include any explanation or extra text.\n",
    "\"\"\"\n",
    "\n",
    "def extract_patient_name(file_path):\n",
    "    \"\"\"Get patient name from JSON or filename.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if isinstance(data, dict) and \"character\" in data:\n",
    "        return data[\"character\"]\n",
    "    return os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "def get_conversation_text(file_path):\n",
    "    \"\"\"Join all dialogue turns into a readable transcript.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    if \"turns\" in data:\n",
    "        return \"\\n\".join([f\"{t['speaker']}: {t['text']}\" for t in data[\"turns\"]])\n",
    "    return json.dumps(data, ensure_ascii=False)\n",
    "\n",
    "def safe_parse_json(text):\n",
    "    \"\"\"Extract a JSON object from possibly messy model output.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            return json.loads(match.group(0))\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def estimate_phq9(file_path):\n",
    "    \"\"\"Send the conversation to GPT and parse PHQ-9 scores.\"\"\"\n",
    "    conversation = get_conversation_text(file_path)\n",
    "\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=MODEL_NAME,\n",
    "            input=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a clinical assessment assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": PHQ9_PROMPT + \"\\n\\nConversation:\\n\" + conversation}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        # New SDK: extract full text output correctly\n",
    "        output_text = \"\"\n",
    "        for output_item in response.output:\n",
    "            if hasattr(output_item, \"content\"):\n",
    "                for content_part in output_item.content:\n",
    "                    if getattr(content_part, \"type\", None) == \"output_text\":\n",
    "                        output_text += content_part.text\n",
    "\n",
    "        scores = safe_parse_json(output_text)\n",
    "        if not scores:\n",
    "            raise ValueError(\"Model returned no valid JSON.\")\n",
    "        return scores\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error parsing response for {file_path}: {e}\")\n",
    "        return {f\"Q{i}\": None for i in range(1, 10)} | {\"Total\": None}\n",
    "\n",
    "def main():\n",
    "    files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith(\".json\")]\n",
    "    all_results = []\n",
    "\n",
    "    for idx, file_name in enumerate(files, start=1):\n",
    "        file_path = os.path.join(INPUT_FOLDER, file_name)\n",
    "        patient_name = extract_patient_name(file_path)\n",
    "        scores = estimate_phq9(file_path)\n",
    "        row = {\"No.\": idx, \"Name\": patient_name, **scores}\n",
    "        all_results.append(row)\n",
    "        print(f\"Processed {patient_name} → Total Score: {scores.get('Total')}\")\n",
    "\n",
    "    # Write results\n",
    "    fieldnames = [\"No.\", \"Name\"] + [f\"Q{i}\" for i in range(1, 10)] + [\"Total\"]\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_results)\n",
    "\n",
    "    print(f\"\\n✅ Results saved to {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
