{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6bd698",
   "metadata": {},
   "source": [
    "## PHQ-9 Conversations Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24eaeb2a",
   "metadata": {},
   "source": [
    "PHQ-9 Queations Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eceb5405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Ahmed Noor → Total Score: 20\n",
      "Processed Aiden Brooks → Total Score: 15\n",
      "Processed Aiden Harris → Total Score: 17\n",
      "Processed Aiden Scott → Total Score: 17\n",
      "Processed Aisha Rashid → Total Score: 9\n",
      "Processed Alice Johnson → Total Score: 3\n",
      "Processed Alice Williams → Total Score: 18\n",
      "Processed Alyssa Hall → Total Score: 18\n",
      "Processed Alyssa Scott → Total Score: 19\n",
      "Processed Amber Reed → Total Score: 17\n",
      "Processed Amelia Green → Total Score: 17\n",
      "Processed Amelia Harris → Total Score: 18\n",
      "Processed Amira El-Sayed → Total Score: 15\n",
      "Processed Anabelle King → Total Score: 16\n",
      "Processed Andrew Martinez → Total Score: 15\n",
      "Processed Anika Patel → Total Score: 5\n",
      "Processed Anna Morgan → Total Score: 15\n",
      "Processed Ava Brooks → Total Score: 17\n",
      "Processed Ava Brown → Total Score: 18\n",
      "Processed Ava Jensen → Total Score: 15\n",
      "Processed Ava Martin → Total Score: 17\n",
      "Processed Ava Martinez → Total Score: 15\n",
      "Processed Ava Wilson → Total Score: 18\n",
      "Processed Avery Morgan → Total Score: 16\n",
      "Processed Avery Rivera → Total Score: 17\n",
      "Processed Benjamin Hall → Total Score: 17\n",
      "Processed Ben Cooper → Total Score: 15\n",
      "Processed Brian Lee → Total Score: 1\n",
      "Processed Caleb Brooks → Total Score: 15\n",
      "Processed Caleb Thompson → Total Score: 17\n",
      "Processed Carlos Rodriguez → Total Score: 7\n",
      "Processed Carmen Rodriguez → Total Score: 16\n",
      "Processed Carter James → Total Score: 17\n",
      "Processed Carter Scott → Total Score: 15\n",
      "Processed Charles Lee → Total Score: 0\n",
      "Processed Charlie Johnson → Total Score: 16\n",
      "Processed Charlotte Lewis → Total Score: 17\n",
      "Processed Charlotte White → Total Score: 13\n",
      "Processed Chloe Adams → Total Score: 18\n",
      "Processed Chloe Davis → Total Score: 17\n",
      "Processed Chloe Simmons → Total Score: 5\n",
      "Processed Chloe White → Total Score: 18\n",
      "Processed Chloe Yang → Total Score: 16\n",
      "Processed Christopher Baker → Total Score: 18\n",
      "Processed Clara Taylor → Total Score: 21\n",
      "Processed Clara Wang → Total Score: 17\n",
      "Processed Colin Nash → Total Score: 13\n",
      "Processed Daniel Brown → Total Score: 17\n",
      "Processed Daniel Carter → Total Score: 16\n",
      "Processed Daniel Johnson → Total Score: 15\n",
      "Processed Daniel Martinez → Total Score: 18\n",
      "Processed David Brown → Total Score: 4\n",
      "Processed David Chen → Total Score: 8\n",
      "Processed David Johnson → Total Score: 21\n",
      "Processed David Kim → Total Score: 17\n",
      "Processed David Smith → Total Score: 18\n",
      "Processed Derek Lee → Total Score: 17\n",
      "Processed Derek Wallace → Total Score: 18\n",
      "Processed Elaine Carter → Total Score: 3\n",
      "Processed Eleanor Hughes → Total Score: 18\n",
      "Processed Elijah Bennett → Total Score: 17\n",
      "Processed Elijah James → Total Score: 17\n",
      "Processed Elijah West → Total Score: 16\n",
      "Processed Ella Johnson → Total Score: 10\n",
      "Processed Ella Kim → Total Score: 10\n",
      "Processed Ella Mitchell → Total Score: 17\n",
      "Processed Ella Roberts → Total Score: 19\n",
      "Processed Ella Thompson → Total Score: 18\n",
      "Processed Ella Walker → Total Score: 17\n",
      "Processed Emily Harris → Total Score: 17\n",
      "Processed Emily Johnson → Total Score: 3\n",
      "Processed Emily Turner → Total Score: 15\n",
      "Processed Emily White → Total Score: 17\n",
      "Processed Emma Hughes → Total Score: 8\n",
      "Processed Emma Rogers → Total Score: 17\n",
      "Processed Emma Thompson → Total Score: 17\n",
      "Processed Ethan Brooks → Total Score: 16\n",
      "Processed Ethan Brown → Total Score: 17\n",
      "Processed Ethan Reed → Total Score: 19\n",
      "Processed Ethan Smith → Total Score: 17\n",
      "Processed Eva Morales → Total Score: 3\n",
      "Processed Evelyn Sanchez → Total Score: 19\n",
      "Processed Evelyn Taylor → Total Score: 16\n",
      "Processed Fatima Nasser → Total Score: 9\n",
      "Processed Fiona Brown → Total Score: 18\n",
      "Processed Fiona O'Connor → Total Score: 17\n",
      "Processed Franklin Ng → Total Score: 2\n",
      "Processed Gabriel Harris → Total Score: 15\n",
      "Processed Gabriel Parker → Total Score: 17\n",
      "Processed Gabriel Williams → Total Score: 12\n",
      "Processed Gary Fisher → Total Score: 20\n",
      "Processed Grace Martinez → Total Score: 20\n",
      "Processed Grace O’Malley → Total Score: 17\n",
      "Processed Grace Thompson → Total Score: 11\n",
      "Processed Grace Wilson → Total Score: 17\n",
      "Processed Gregory White → Total Score: 2\n",
      "Processed Hannah Patel → Total Score: 17\n",
      "Processed Henry Adams → Total Score: 17\n",
      "Processed Henry Brown → Total Score: 18\n",
      "Processed Henry Thompson → Total Score: 3\n",
      "Processed Isaac Lee → Total Score: 17\n",
      "Processed Isaac Nelson → Total Score: 15\n",
      "Processed Isaac Rivera → Total Score: 16\n",
      "Processed Isabella Chang → Total Score: 16\n",
      "Processed Isabella Chen → Total Score: 17\n",
      "Processed Isabella Garcia → Total Score: 17\n",
      "Processed Isabella Green → Total Score: 14\n",
      "Processed Isabella Scott → Total Score: 20\n",
      "Processed Isabella Torres → Total Score: 13\n",
      "Processed Isaiah Lewis → Total Score: 17\n",
      "Processed Jack Carter → Total Score: 18\n",
      "Processed Jack Turner → Total Score: 15\n",
      "Processed Jacob Brown → Total Score: 16\n",
      "Processed Jacob Smith → Total Score: 19\n",
      "Processed Jacob Wilson → Total Score: 17\n",
      "Processed Jake Patel → Total Score: 9\n",
      "Processed Jameson Lee → Total Score: 18\n",
      "Processed James Anderson → Total Score: 17\n",
      "Processed James Lee → Total Score: 21\n",
      "Processed James Martinez → Total Score: 19\n",
      "Processed James Miller → Total Score: 22\n",
      "Processed James Patel → Total Score: 11\n",
      "Processed Jamila Al-Farsi → Total Score: 8\n",
      "Processed Jaxon Brown → Total Score: 16\n",
      "Processed Jessica Thompson → Total Score: 7\n",
      "Processed Josephine Wright → Total Score: 16\n",
      "Processed Joshua Wilson → Total Score: 18\n",
      "Processed Julia Miller → Total Score: 16\n",
      "Processed Katherine Brown → Total Score: 5\n",
      "Processed Katherine Evans → Total Score: 16\n",
      "Processed Kevin Martinez → Total Score: 5\n",
      "Processed Kyle Smith → Total Score: 17\n",
      "Processed Kylie Smith → Total Score: 15\n",
      "Processed Laura Chen → Total Score: 2\n",
      "Processed Layla Martinez → Total Score: 15\n",
      "Processed Leah King → Total Score: 14\n",
      "Processed Leo Garcia → Total Score: 15\n",
      "Processed Leo Patel → Total Score: 18\n",
      "Processed Liam Brooks → Total Score: 3\n",
      "Processed Liam Clark → Total Score: 17\n",
      "Processed Liam Martinez → Total Score: 17\n",
      "Processed Liam Murphy → Total Score: 17\n",
      "Processed Liam O'Connor → Total Score: 16\n",
      "Processed Liam O'Reilly → Total Score: 16\n",
      "Processed Lila Zhang → Total Score: 19\n",
      "Processed Lily Collins → Total Score: 17\n",
      "Processed Lily Martin → Total Score: 16\n",
      "Processed Lily Rodriguez → Total Score: 17\n",
      "Processed Lisa Kim → Total Score: 3\n",
      "Processed Logan Hall → Total Score: 17\n",
      "Processed Lucas Anderson → Total Score: 15\n",
      "Processed Lucas Brown → Total Score: 10\n",
      "Processed Lucas Harris → Total Score: 17\n",
      "Processed Lucas Thompson → Total Score: 19\n",
      "Processed Lucy Allen → Total Score: 19\n",
      "Processed Lucy Kim → Total Score: 17\n",
      "Processed Luna Carter → Total Score: 17\n",
      "Processed Madison Cooper → Total Score: 19\n",
      "Processed Madison King → Total Score: 15\n",
      "Processed Marcus Delgado → Total Score: 19\n",
      "Processed Marcus Wright → Total Score: 8\n",
      "Processed Mason Hall → Total Score: 15\n",
      "Processed Mason Lopez → Total Score: 16\n",
      "Processed Matthew Davis → Total Score: 18\n",
      "Processed Matthew Sullivan → Total Score: 16\n",
      "Processed Matthew Turner → Total Score: 17\n",
      "Processed Maxwell Garcia → Total Score: 7\n",
      "Processed Maya Johnson → Total Score: 13\n",
      "Processed Maya Patel → Total Score: 17\n",
      "Processed Maya Scott → Total Score: 16\n",
      "Processed Maya Thompson → Total Score: 17\n",
      "Processed Megan Sanchez → Total Score: 18\n",
      "Processed Megan White → Total Score: 14\n",
      "Processed Mia Collins → Total Score: 17\n",
      "Processed Mia Davis → Total Score: 16\n",
      "Processed Mia Patel → Total Score: 18\n",
      "Processed Mia Robinson → Total Score: 16\n",
      "Processed Michael Harris → Total Score: 17\n",
      "Processed Michael Lee → Total Score: 3\n",
      "Processed Michael Lopez → Total Score: 15\n",
      "Processed Michael Reyes → Total Score: 9\n",
      "Processed Natalia Sokolov → Total Score: 17\n",
      "Processed Natalie Green → Total Score: 4\n",
      "Processed Natalie Lewis → Total Score: 17\n",
      "Processed Natalie Reynolds → Total Score: 8\n",
      "Processed Nathaniel Carter → Total Score: 16\n",
      "Processed Nathan Cruz → Total Score: 17\n",
      "Processed Nelson Carter → Total Score: 4\n",
      "Processed Nina Alvarez → Total Score: 17\n",
      "Processed Noah Johnson → Total Score: 17\n",
      "Processed Noah Roberts → Total Score: 18\n",
      "Processed Noah Thompson → Total Score: 10\n",
      "Processed Nora Bell → Total Score: 16\n",
      "Processed Nora Cummings → Total Score: 20\n",
      "Processed Oliver Chen → Total Score: 15\n",
      "Processed Oliver Knight → Total Score: 17\n",
      "Processed Oliver Nelson → Total Score: 18\n",
      "Processed Oliver Ramirez → Total Score: 14\n",
      "Processed Oliver Scott → Total Score: 16\n",
      "Processed Oliver Young → Total Score: 21\n",
      "Processed Olivia Chen → Total Score: 17\n",
      "Processed Olivia Martinez → Total Score: 3\n",
      "Processed Olivia Rodriguez → Total Score: 20\n",
      "Processed Olivia Wright → Total Score: 13\n",
      "Processed Omar Khatib → Total Score: 7\n",
      "Processed Owen Thompson → Total Score: 15\n",
      "Processed Patricia Jones → Total Score: 3\n",
      "Processed Patrick O'Reilly → Total Score: 16\n",
      "Processed Piper Evans → Total Score: 17\n",
      "Processed Quinn Harrison → Total Score: 14\n",
      "Processed Raymond Fields → Total Score: 3\n",
      "Processed Robert Johnson → Total Score: 17\n",
      "Processed Ronald Hughes → Total Score: 3\n",
      "Processed Ryan Lee → Total Score: 16\n",
      "Processed Ryan Thompson → Total Score: 18\n",
      "Processed Samantha King → Total Score: 15\n",
      "Processed Samuel Garcia → Total Score: 19\n",
      "Processed Samuel Green → Total Score: 14\n",
      "Processed Samuel Rivera → Total Score: 17\n",
      "Processed Samuel Young → Total Score: 18\n",
      "Processed Sam Robinson → Total Score: 14\n",
      "Processed Sandra Lee → Total Score: 5\n",
      "Processed Sarah Kim → Total Score: 1\n",
      "Processed Sara Thomas → Total Score: 17\n",
      "Processed Scarlett Hill → Total Score: 17\n",
      "Processed Sharon Ellis → Total Score: 17\n",
      "Processed Sofia Martinez → Total Score: 16\n",
      "Processed Sofia Patel → Total Score: 18\n",
      "Processed Sofia Rivera → Total Score: 18\n",
      "Processed Sophia Bennett → Total Score: 18\n",
      "Processed Sophia Carter → Total Score: 16\n",
      "Processed Sophia Garcia → Total Score: 17\n",
      "Processed Sophia Kim → Total Score: 17\n",
      "Processed Sophia Patterson → Total Score: 17\n",
      "Processed Sophia Wang → Total Score: 17\n",
      "Processed Sophie Lee → Total Score: 17\n",
      "Processed Sophie Nguyen → Total Score: 6\n",
      "Processed Susan White → Total Score: 13\n",
      "Processed Tanya Nguyen → Total Score: 6\n",
      "Processed Thomas Brooks → Total Score: 15\n",
      "Processed Thomas Green → Total Score: 7\n",
      "Processed Thomas White → Total Score: 15\n",
      "Processed Tom Nguyen → Total Score: 16\n",
      "Processed Tom Sullivan → Total Score: 3\n",
      "Processed Tyler Scott → Total Score: 17\n",
      "Processed Ursula Flowers → Total Score: 18\n",
      "Processed Victoria Moore → Total Score: 17\n",
      "Processed Victoria Wilson → Total Score: 18\n",
      "Processed Victoria Young → Total Score: 15\n",
      "Processed Victor Nguyen → Total Score: 7\n",
      "Processed Victor Ramirez → Total Score: 2\n",
      "Processed Vincent Ali → Total Score: 18\n",
      "Processed Wendy Wallace → Total Score: 15\n",
      "Processed William Carter → Total Score: 17\n",
      "Processed William Clark → Total Score: 19\n",
      "Processed Xavier Lopez → Total Score: 17\n",
      "Processed Xavier Thomas → Total Score: 17\n",
      "Processed Yvonne Grant → Total Score: 17\n",
      "Processed Zachary Martin → Total Score: 17\n",
      "Processed Zachary Young → Total Score: 16\n",
      "Processed Zara Khan → Total Score: 10\n",
      "Processed Zoey White → Total Score: 16\n",
      "Processed Zoe Green → Total Score: 17\n",
      "Processed Zoe Patel → Total Score: 18\n",
      "Processed Zoe Turner → Total Score: 17\n",
      "Processed Zoe Wilson → Total Score: 16\n",
      "\n",
      "✅ Saved summary to Analysis/PHQ9/Questionnaire_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_FOLDER = \"Conversations/PHQ9/Question based Conversation/\"        # folder containing all patient JSON files\n",
    "OUTPUT_CSV = \"Analysis/PHQ9/Questionnaire_summary.csv\"     # output summary file\n",
    "# -----------------------------\n",
    "\n",
    "def extract_patient_name(file_path):\n",
    "    \"\"\"Get patient name from JSON or filename.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    # most files have the patient’s name as the first key of \"Common Questions\"\n",
    "    if \"Common Questions\" in data and len(data[\"Common Questions\"]) > 0:\n",
    "        first_item = data[\"Common Questions\"][0]\n",
    "        for k in first_item.keys():\n",
    "            if k.lower() not in (\"consultant\",):\n",
    "                return k.strip()\n",
    "    # fallback to filename\n",
    "    return os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "def extract_ratings(file_path):\n",
    "    \"\"\"Extract 9 PHQ-9 ratings from Ava_Brooks-style JSON.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    ratings = []\n",
    "    if \"Common Questions\" in data:\n",
    "        for item in data[\"Common Questions\"]:\n",
    "            # each question is a dict with 'Consultant' and '<Name>'\n",
    "            for k, v in item.items():\n",
    "                if k.lower() != \"consultant\" and isinstance(v, str):\n",
    "                    # find rating numbers like \"Rating: 2\", \"rated it 3\", \"2—More\"\n",
    "                    match = re.search(r\"\\b([0-3])\\b\", v)\n",
    "                    if match:\n",
    "                        ratings.append(int(match.group(1)))\n",
    "                    else:\n",
    "                        ratings.append(None)\n",
    "    # Ensure exactly 9 ratings\n",
    "    ratings = (ratings + [None]*9)[:9]\n",
    "    return ratings\n",
    "\n",
    "def main():\n",
    "    files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith(\".json\")]\n",
    "    all_rows = []\n",
    "\n",
    "    for idx, file_name in enumerate(files, start=1):\n",
    "        file_path = os.path.join(INPUT_FOLDER, file_name)\n",
    "        name = extract_patient_name(file_path)\n",
    "        ratings = extract_ratings(file_path)\n",
    "        total = sum(r for r in ratings if isinstance(r, int))\n",
    "        row = {\"No.\": idx, \"Name\": name}\n",
    "        for i, r in enumerate(ratings, start=1):\n",
    "            row[f\"Q{i}\"] = r\n",
    "        row[\"Total\"] = total\n",
    "        all_rows.append(row)\n",
    "        print(f\"Processed {name} → Total Score: {total}\")\n",
    "\n",
    "    # Write CSV\n",
    "    fieldnames = [\"No.\", \"Name\"] + [f\"Q{i}\" for i in range(1, 10)] + [\"Total\"]\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_rows)\n",
    "\n",
    "    print(f\"\\n✅ Saved summary to {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4087630e",
   "metadata": {},
   "source": [
    "Casual Conversation Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92aa94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, csv, re\n",
    "from openai import OpenAI\n",
    "\n",
    "# -----------------------\n",
    "# CONFIG\n",
    "# -----------------------\n",
    "INPUT_FOLDER = \"Conversations/PHQ9/Normal Conversation/\"\n",
    "OUTPUT_CSV = \"Analysis/PHQ9/Conversation_summary.csv\"\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "You are an AI trained to assess depression severity from natural conversations,\n",
    "NOT by using the PHQ-9, but by analyzing real emotional, cognitive, and behavioral patterns.\n",
    "\n",
    "Evaluate the PERSON's depression based ONLY on their spoken content in the transcript.\n",
    "\n",
    "Assess these clinical dimensions, each 0-3:\n",
    "- Mood & emotional tone (sadness, emptiness, hopelessness)\n",
    "- Anhedonia (loss of interest/joy)\n",
    "- Energy/fatigue\n",
    "- Motivation / initiative\n",
    "- Sleep disturbance\n",
    "- Appetite or weight changes\n",
    "- Cognitive difficulty (focus, decision-making, fogginess)\n",
    "- Psychomotor change (slowed, restless)\n",
    "- Self-worth / guilt / self-criticism\n",
    "- Suicidal ideation / morbid thoughts (if expressed)\n",
    "\n",
    "Scoring key per item:\n",
    "0 = none\n",
    "1 = mild / occasional\n",
    "2 = moderate or frequent\n",
    "3 = severe / nearly constant / disabling\n",
    "\n",
    "Return JSON ONLY in this format:\n",
    "\n",
    "{\n",
    "  \"Mood\": <0-3>,\n",
    "  \"Anhedonia\": <0-3>,\n",
    "  \"Energy\": <0-3>,\n",
    "  \"Motivation\": <0-3>,\n",
    "  \"Sleep\": <0-3>,\n",
    "  \"Appetite\": <0-3>,\n",
    "  \"Cognition\": <0-3>,\n",
    "  \"Psychomotor\": <0-3>,\n",
    "  \"SelfWorth\": <0-3>,\n",
    "  \"Suicidality\": <0-3>,\n",
    "  \"Total\": <0-27>,\n",
    "  \"Confidence\": \"<low/medium/high>\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def extract_text(path):\n",
    "    data = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
    "    return \"\\n\".join([f\"{t['speaker']}: {t['text']}\" for t in data.get(\"turns\", [])])\n",
    "\n",
    "def parse_json(txt):\n",
    "    m = re.search(r\"\\{.*\\}\", txt, re.DOTALL)\n",
    "    if not m: return None\n",
    "    try: return json.loads(m.group(0))\n",
    "    except: return None\n",
    "\n",
    "def score_file(path):\n",
    "    text = extract_text(path)\n",
    "\n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a clinical conversational inference model.\"},\n",
    "            {\"role\": \"user\", \"content\": PROMPT + \"\\n\\nConversation:\\n\" + text}\n",
    "        ],\n",
    "        temperature=0\n",
    "    ).choices[0].message.content\n",
    "\n",
    "    scores = parse_json(r)\n",
    "    return scores\n",
    "\n",
    "def main():\n",
    "    os.makedirs(os.path.dirname(OUTPUT_CSV), exist_ok=True)\n",
    "\n",
    "    results = []\n",
    "    files = [f for f in os.listdir(INPUT_FOLDER) if f.endswith(\".json\")]\n",
    "\n",
    "    for i, f in enumerate(files, 1):\n",
    "        name = f.replace(\".json\", \"\")\n",
    "        try:\n",
    "            s = score_file(os.path.join(INPUT_FOLDER, f))\n",
    "            if not s:\n",
    "                print(f\"⚠️ {name}: failed — retry manually\"); continue\n",
    "            results.append({\"Name\": name, **s})\n",
    "            print(f\"✓ {name}: CDI={s['Total']} ({s['Confidence']})\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ {name}: {e}\")\n",
    "\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as out:\n",
    "        writer = csv.DictWriter(out, fieldnames=results[0].keys())\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n",
    "\n",
    "    print(f\"\\n✅ Saved → {OUTPUT_CSV}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07297235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ahmed Noor: CDI=18 (high)\n",
      "✓ Aiden Brooks: CDI=9 (high)\n",
      "✓ Aiden Harris: CDI=9 (high)\n",
      "✓ Aiden Scott: CDI=12 (high)\n",
      "✓ Aisha Rashid: CDI=9 (high)\n",
      "✓ Alice Johnson: CDI=0 (high)\n",
      "✓ Alice Williams: CDI=9 (high)\n",
      "✓ Alyssa Hall: CDI=13 (high)\n",
      "✓ Alyssa Scott: CDI=14 (high)\n",
      "✓ Amber Reed: CDI=14 (high)\n",
      "✓ Amelia Green: CDI=15 (high)\n",
      "✓ Amelia Harris: CDI=15 (high)\n",
      "✓ Amira El-Sayed: CDI=13 (high)\n",
      "✓ Anabelle King: CDI=10 (high)\n",
      "✓ Andrew Martinez: CDI=9 (high)\n",
      "✓ Anika Patel: CDI=7 (high)\n",
      "✓ Anna Morgan: CDI=10 (high)\n",
      "✓ Ava Brooks: CDI=14 (high)\n",
      "✓ Ava Brown: CDI=13 (high)\n",
      "✓ Ava Jensen: CDI=15 (high)\n",
      "✓ Ava Martin: CDI=9 (high)\n",
      "✓ Ava Martinez: CDI=13 (high)\n",
      "✓ Ava Wilson: CDI=17 (high)\n",
      "✓ Avery Morgan: CDI=7 (high)\n",
      "✓ Avery Rivera: CDI=14 (high)\n",
      "✓ Ben Cooper: CDI=14 (high)\n",
      "✓ Benjamin Hall: CDI=15 (high)\n",
      "✓ Brian Lee: CDI=2 (high)\n",
      "✓ Caleb Brooks: CDI=16 (high)\n",
      "✓ Caleb Thompson: CDI=15 (high)\n",
      "✓ Carlos Rodriguez: CDI=6 (high)\n",
      "✓ Carmen Rodriguez: CDI=12 (high)\n",
      "✓ Carter James: CDI=12 (high)\n",
      "✓ Carter Scott: CDI=15 (high)\n",
      "✓ Charles Lee: CDI=0 (high)\n",
      "✓ Charlie Johnson: CDI=9 (high)\n",
      "✓ Charlotte Lewis: CDI=16 (high)\n",
      "✓ Charlotte White: CDI=9 (high)\n",
      "✓ Chloe Adams: CDI=7 (high)\n",
      "✓ Chloe Davis: CDI=10 (high)\n",
      "✓ Chloe Simmons: CDI=5 (high)\n",
      "✓ Chloe White: CDI=14 (high)\n",
      "✓ Chloe Yang: CDI=10 (high)\n",
      "✓ Christopher Baker: CDI=15 (high)\n",
      "✓ Clara Taylor: CDI=16 (high)\n",
      "✓ Clara Wang: CDI=15 (high)\n",
      "✓ Colin Nash: CDI=10 (high)\n",
      "✓ Daniel Brown: CDI=16 (high)\n",
      "✓ Daniel Carter: CDI=13 (high)\n",
      "✓ Daniel Johnson: CDI=12 (high)\n",
      "✓ Daniel Martinez: CDI=14 (high)\n",
      "✓ David Brown: CDI=5 (high)\n",
      "✓ David Chen: CDI=8 (high)\n",
      "✓ David Johnson: CDI=15 (high)\n",
      "✓ David Kim: CDI=9 (high)\n",
      "✓ David Smith: CDI=16 (high)\n",
      "✓ Derek Lee: CDI=12 (high)\n",
      "✓ Derek Wallace: CDI=14 (high)\n",
      "✓ Elaine Carter: CDI=4 (high)\n",
      "✓ Eleanor Hughes: CDI=15 (high)\n",
      "✓ Elijah Bennett: CDI=15 (high)\n",
      "✓ Elijah James: CDI=16 (high)\n",
      "✓ Elijah West: CDI=9 (high)\n",
      "✓ Ella Johnson: CDI=6 (high)\n",
      "✓ Ella Kim: CDI=10 (high)\n",
      "✓ Ella Mitchell: CDI=15 (high)\n",
      "✓ Ella Roberts: CDI=16 (high)\n",
      "✓ Ella Thompson: CDI=17 (high)\n",
      "✓ Ella Walker: CDI=12 (high)\n",
      "✓ Emily Harris: CDI=15 (high)\n",
      "✓ Emily Johnson: CDI=0 (high)\n",
      "✓ Emily Turner: CDI=15 (high)\n",
      "✓ Emily White: CDI=15 (high)\n",
      "✓ Emma Hughes: CDI=6 (high)\n",
      "✓ Emma Rogers: CDI=13 (high)\n",
      "✓ Emma Thompson: CDI=16 (high)\n",
      "✓ Ethan Brooks: CDI=15 (high)\n",
      "✓ Ethan Brown: CDI=17 (high)\n",
      "✓ Ethan Reed: CDI=16 (high)\n",
      "✓ Ethan Smith: CDI=12 (high)\n",
      "✓ Eva Morales: CDI=1 (high)\n",
      "✓ Evelyn Sanchez: CDI=13 (high)\n",
      "✓ Evelyn Taylor: CDI=9 (high)\n",
      "✓ Fatima Nasser: CDI=8 (high)\n",
      "✓ Fiona Brown: CDI=16 (high)\n",
      "✓ Fiona O'Connor: CDI=9 (high)\n",
      "✓ Franklin Ng: CDI=0 (high)\n",
      "✓ Gabriel Harris: CDI=10 (high)\n",
      "✓ Gabriel Parker: CDI=14 (high)\n",
      "✓ Gabriel Williams: CDI=11 (high)\n",
      "✓ Gary Fisher: CDI=15 (high)\n",
      "✓ Grace Martinez: CDI=12 (high)\n",
      "✓ Grace O’Malley: CDI=15 (high)\n",
      "✓ Grace Thompson: CDI=8 (high)\n",
      "✓ Grace Wilson: CDI=12 (high)\n",
      "✓ Gregory White: CDI=7 (high)\n",
      "✓ Hannah Patel: CDI=9 (high)\n",
      "✓ Henry Adams: CDI=11 (high)\n",
      "✓ Henry Brown: CDI=14 (high)\n",
      "✓ Henry Thompson: CDI=4 (high)\n",
      "✓ Isaac Lee: CDI=13 (high)\n",
      "✓ Isaac Nelson: CDI=13 (high)\n",
      "✓ Isaac Rivera: CDI=13 (high)\n",
      "✓ Isabella Chang: CDI=14 (high)\n",
      "✓ Isabella Chen: CDI=14 (high)\n",
      "✓ Isabella Garcia: CDI=15 (high)\n",
      "✓ Isabella Green: CDI=10 (high)\n",
      "✓ Isabella Scott: CDI=16 (high)\n",
      "✓ Isabella Torres: CDI=9 (high)\n",
      "✓ Isaiah Lewis: CDI=15 (high)\n",
      "✓ Jack Carter: CDI=15 (high)\n",
      "✓ Jack Turner: CDI=10 (high)\n",
      "✓ Jacob Brown: CDI=16 (high)\n",
      "✓ Jacob Smith: CDI=15 (high)\n",
      "✓ Jacob Wilson: CDI=13 (high)\n",
      "✓ Jake Patel: CDI=9 (high)\n",
      "✓ James Anderson: CDI=12 (high)\n",
      "✓ James Lee: CDI=16 (high)\n",
      "✓ James Martinez: CDI=17 (high)\n",
      "✓ James Miller: CDI=16 (high)\n",
      "✓ James Patel: CDI=9 (high)\n",
      "✓ Jameson Lee: CDI=16 (high)\n",
      "✓ Jamila Al-Farsi: CDI=9 (high)\n",
      "✓ Jaxon Brown: CDI=10 (high)\n",
      "✓ Jessica Thompson: CDI=9 (high)\n",
      "✓ Josephine Wright: CDI=12 (high)\n",
      "✓ Joshua Wilson: CDI=14 (high)\n",
      "✓ Julia Miller: CDI=9 (high)\n",
      "✓ Katherine Brown: CDI=6 (high)\n",
      "✓ Katherine Evans: CDI=9 (high)\n",
      "✓ Kevin Martinez: CDI=7 (high)\n",
      "✓ Kyle Smith: CDI=16 (high)\n",
      "✓ Kylie Smith: CDI=14 (high)\n",
      "✓ Laura Chen: CDI=8 (high)\n",
      "✓ Layla Martinez: CDI=12 (high)\n",
      "✓ Leah King: CDI=12 (high)\n",
      "✓ Leo Garcia: CDI=13 (high)\n",
      "✓ Leo Patel: CDI=12 (high)\n",
      "✓ Liam Brooks: CDI=7 (high)\n",
      "✓ Liam Clark: CDI=15 (high)\n",
      "✓ Liam Martinez: CDI=13 (high)\n",
      "✓ Liam Murphy: CDI=13 (high)\n",
      "✓ Liam O'Connor: CDI=14 (high)\n",
      "✓ Liam O'Reilly: CDI=8 (high)\n",
      "✓ Lila Zhang: CDI=14 (high)\n",
      "✓ Lily Collins: CDI=8 (high)\n",
      "✓ Lily Martin: CDI=11 (high)\n",
      "✓ Lily Rodriguez: CDI=14 (high)\n",
      "✓ Lisa Kim: CDI=7 (high)\n",
      "✓ Logan Hall: CDI=9 (high)\n",
      "✓ Lucas Anderson: CDI=11 (high)\n",
      "✓ Lucas Brown: CDI=8 (high)\n",
      "✓ Lucas Harris: CDI=13 (high)\n",
      "✓ Lucas Thompson: CDI=17 (high)\n",
      "✓ Lucy Allen: CDI=17 (high)\n",
      "✓ Lucy Kim: CDI=14 (high)\n",
      "✓ Luna Carter: CDI=11 (high)\n",
      "✓ Madison Cooper: CDI=15 (high)\n",
      "✓ Madison King: CDI=9 (high)\n",
      "✓ Marcus Delgado: CDI=15 (high)\n",
      "✓ Marcus Wright: CDI=9 (high)\n",
      "✓ Mason Hall: CDI=11 (high)\n",
      "✓ Mason Lopez: CDI=10 (high)\n",
      "✓ Matthew Davis: CDI=13 (high)\n",
      "✓ Matthew Sullivan: CDI=11 (high)\n",
      "✓ Matthew Turner: CDI=15 (high)\n",
      "✓ Maxwell Garcia: CDI=4 (high)\n",
      "✓ Maya Johnson: CDI=9 (high)\n",
      "✓ Maya Patel: CDI=13 (high)\n",
      "✓ Maya Scott: CDI=12 (high)\n",
      "✓ Maya Thompson: CDI=11 (high)\n",
      "✓ Megan Sanchez: CDI=15 (high)\n",
      "✓ Megan White: CDI=14 (high)\n",
      "✓ Mia Collins: CDI=15 (high)\n",
      "✓ Mia Davis: CDI=14 (high)\n",
      "✓ Mia Patel: CDI=12 (high)\n",
      "✓ Mia Robinson: CDI=15 (high)\n",
      "✓ Michael Harris: CDI=15 (high)\n",
      "✓ Michael Lee: CDI=0 (high)\n",
      "✓ Michael Lopez: CDI=15 (high)\n",
      "✓ Michael Reyes: CDI=9 (high)\n",
      "✓ Natalia Sokolov: CDI=15 (high)\n",
      "✓ Natalie Green: CDI=6 (high)\n",
      "✓ Natalie Lewis: CDI=15 (high)\n",
      "✓ Natalie Reynolds: CDI=7 (high)\n",
      "✓ Nathan Cruz: CDI=12 (high)\n",
      "✓ Nathaniel Carter: CDI=9 (high)\n",
      "✓ Nelson Carter: CDI=4 (high)\n",
      "✓ Nina Alvarez: CDI=14 (high)\n",
      "✓ Noah Johnson: CDI=16 (high)\n",
      "✓ Noah Roberts: CDI=15 (high)\n",
      "✓ Noah Thompson: CDI=7 (high)\n",
      "✓ Nora Bell: CDI=13 (high)\n",
      "✓ Nora Cummings: CDI=14 (high)\n",
      "✓ Oliver Chen: CDI=9 (high)\n",
      "✓ Oliver Knight: CDI=11 (high)\n",
      "✓ Oliver Nelson: CDI=14 (high)\n",
      "✓ Oliver Ramirez: CDI=15 (high)\n",
      "✓ Oliver Scott: CDI=13 (high)\n",
      "✓ Oliver Young: CDI=13 (high)\n",
      "✓ Olivia Chen: CDI=14 (high)\n",
      "✓ Olivia Martinez: CDI=8 (high)\n",
      "✓ Olivia Rodriguez: CDI=14 (high)\n",
      "✓ Olivia Wright: CDI=9 (high)\n",
      "✓ Omar Khatib: CDI=9 (high)\n",
      "✓ Owen Thompson: CDI=11 (high)\n",
      "✓ Patricia Jones: CDI=6 (high)\n",
      "✓ Patrick O'Reilly: CDI=11 (high)\n",
      "✓ Piper Evans: CDI=13 (high)\n",
      "✓ Quinn Harrison: CDI=13 (high)\n",
      "✓ Raymond Fields: CDI=7 (high)\n",
      "✓ Robert Johnson: CDI=11 (high)\n",
      "✓ Ronald Hughes: CDI=5 (high)\n",
      "✓ Ryan Lee: CDI=14 (high)\n",
      "✓ Ryan Thompson: CDI=13 (high)\n",
      "✓ Sam Robinson: CDI=10 (high)\n",
      "✓ Samantha King: CDI=14 (high)\n",
      "✓ Samuel Garcia: CDI=16 (high)\n",
      "✓ Samuel Green: CDI=10 (high)\n",
      "✓ Samuel Rivera: CDI=15 (high)\n",
      "✓ Samuel Young: CDI=17 (high)\n",
      "✓ Sandra Lee: CDI=5 (high)\n",
      "✓ Sara Thomas: CDI=12 (high)\n",
      "✓ Sarah Kim: CDI=6 (high)\n",
      "✓ Scarlett Hill: CDI=12 (high)\n",
      "✓ Sharon Ellis: CDI=10 (high)\n",
      "✓ Sofia Martinez: CDI=13 (high)\n",
      "✓ Sofia Patel: CDI=16 (high)\n",
      "✓ Sofia Rivera: CDI=15 (high)\n",
      "✓ Sophia Bennett: CDI=12 (high)\n",
      "✓ Sophia Carter: CDI=14 (high)\n",
      "✓ Sophia Garcia: CDI=8 (high)\n",
      "✓ Sophia Kim: CDI=15 (high)\n",
      "✓ Sophia Patterson: CDI=15 (high)\n",
      "✓ Sophia Wang: CDI=15 (high)\n",
      "✓ Sophie Lee: CDI=9 (high)\n",
      "✓ Sophie Nguyen: CDI=8 (high)\n",
      "✓ Susan White: CDI=9 (high)\n",
      "✓ Tanya Nguyen: CDI=6 (high)\n",
      "✓ Thomas Brooks: CDI=14 (high)\n",
      "✓ Thomas Green: CDI=0 (high)\n",
      "✓ Thomas White: CDI=12 (high)\n",
      "✓ Tom Nguyen: CDI=11 (high)\n",
      "✓ Tom Sullivan: CDI=0 (high)\n",
      "✓ Tyler Scott: CDI=13 (high)\n",
      "✓ Ursula Flowers: CDI=8 (high)\n",
      "✓ Victor Nguyen: CDI=0 (high)\n",
      "✓ Victor Ramirez: CDI=6 (high)\n",
      "✓ Victoria Moore: CDI=13 (high)\n",
      "✓ Victoria Wilson: CDI=14 (high)\n",
      "✓ Victoria Young: CDI=8 (high)\n",
      "✓ Vincent Ali: CDI=16 (high)\n",
      "✓ Wendy Wallace: CDI=11 (high)\n",
      "✓ William Carter: CDI=13 (high)\n",
      "✓ William Clark: CDI=16 (high)\n",
      "✓ Xavier Lopez: CDI=13 (high)\n",
      "✓ Xavier Thomas: CDI=12 (high)\n",
      "✓ Yvonne Grant: CDI=13 (high)\n",
      "✓ Zachary Martin: CDI=12 (high)\n",
      "✓ Zachary Young: CDI=16 (high)\n",
      "✓ Zara Khan: CDI=9 (high)\n",
      "✓ Zoe Green: CDI=14 (high)\n",
      "✓ Zoe Patel: CDI=15 (high)\n",
      "✓ Zoe Turner: CDI=12 (high)\n",
      "✓ Zoe Wilson: CDI=9 (high)\n",
      "✓ Zoey White: CDI=11 (high)\n",
      "✅ Saved summary → Analysis/ConversationOnly\\CDI_scores.csv\n",
      "✅ Saved evidence → Analysis/ConversationOnly\\CDI_evidence.csv\n"
     ]
    }
   ],
   "source": [
    "# conversation_depression_inference_v2.py\n",
    "import os, re, json, csv, time, random\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "INPUT_FOLDER = \"Conversations/PHQ9/Normal Conversation\"\n",
    "OUT_DIR      = \"Analysis/ConversationOnly\"\n",
    "OUT_SUMMARY  = os.path.join(OUT_DIR, \"CDI_scores.csv\")\n",
    "OUT_DETAIL   = os.path.join(OUT_DIR, \"CDI_evidence.csv\")\n",
    "LOG_DIR      = os.path.join(OUT_DIR, \"_logs\")\n",
    "\n",
    "# Use a stronger model for structured inference\n",
    "SCORING_MODEL = \"gpt-4.1-mini\"   # or \"gpt-4.1\" for best reliability\n",
    "TEMPERATURE   = 0.0\n",
    "\n",
    "MAX_CHARS_PER_CHUNK = 9000\n",
    "MAX_RETRIES         = 3\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(LOG_DIR, exist_ok=True)\n",
    "load_dotenv()\n",
    "client = OpenAI()  # expects OPENAI_API_KEY in env\n",
    "\n",
    "# =========================\n",
    "# DOMAINS (no PHQ-9 words)\n",
    "# =========================\n",
    "DOMAINS = [\n",
    "    (\"Mood\",        \"sadness, emptiness, hopelessness\"),\n",
    "    (\"Anhedonia\",   \"loss of interest or joy\"),\n",
    "    (\"Energy\",      \"low energy, fatigue, drained\"),\n",
    "    (\"Motivation\",  \"reduced drive, difficulty initiating tasks\"),\n",
    "    (\"Sleep\",       \"trouble falling or staying asleep, oversleeping\"),\n",
    "    (\"Appetite\",    \"eating less or more than usual, weight change\"),\n",
    "    (\"Cognition\",   \"poor concentration, mind racing, indecisive\"),\n",
    "    (\"Psychomotor\", \"slowed movement/speech or restlessness/fidgeting\"),\n",
    "    (\"SelfWorth\",   \"self-criticism, guilt, worthlessness\"),\n",
    "    (\"Suicidality\", \"thoughts of death or self-harm (frequency only)\"),\n",
    "]\n",
    "\n",
    "DOMAIN_KEYS = [d[0] for d in DOMAINS]\n",
    "\n",
    "# =========================\n",
    "# PROMPTS\n",
    "# =========================\n",
    "SYSTEM_SUMMARY = (\n",
    "    \"You are a careful clinical text rater. You do not diagnose or give advice. \"\n",
    "    \"You only extract evidence signals from a person's natural conversation.\"\n",
    ")\n",
    "\n",
    "USER_SUMMARY_TEMPLATE = \"\"\"\n",
    "Read the person's statements (friend prompts removed). Extract concise evidence for each domain.\n",
    "For each domain, return:\n",
    "- \"present\": true/false\n",
    "- \"frequency\": one of [\"none\",\"occasional\",\"often\",\"nearly daily\"]\n",
    "- \"intensity\": one of [\"none\",\"mild\",\"moderate\",\"severe\"]\n",
    "- \"quotes\": list of 1-3 short paraphrases or brief quotes from the text\n",
    "\n",
    "Domains (9 + suicidality):\n",
    "{domain_bullets}\n",
    "\n",
    "Rules:\n",
    "- Use only the PERSON's lines (the conversation below already excludes the friend).\n",
    "- If no clear evidence, set present=false, frequency=\"none\", intensity=\"none\", quotes=[].\n",
    "- If suicidality is mentioned indirectly, record frequency by how often it appears or is implied.\n",
    "- Output JSON only, no extra text.\n",
    "\n",
    "Conversation (PERSON only):\n",
    "\\\"\\\"\\\"\n",
    "{person_text}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_SCORE = (\n",
    "    \"You are a strict JSON scoring function. You convert evidence into 0-3 scores. \"\n",
    "    \"Do not provide advice or narrative; return JSON only.\"\n",
    ")\n",
    "\n",
    "USER_SCORE_TEMPLATE = \"\"\"\n",
    "Convert the following domain evidence into numeric scores (0–3) using frequency+intensity:\n",
    "\n",
    "0 = none\n",
    "1 = mild / occasional\n",
    "2 = moderate / often\n",
    "3 = severe / nearly daily\n",
    "\n",
    "Domains and evidence (JSON):\n",
    "{evidence_json}\n",
    "\n",
    "Return JSON ONLY:\n",
    "{{\n",
    "  \"Mood\": <0-3>,\n",
    "  \"Anhedonia\": <0-3>,\n",
    "  \"Energy\": <0-3>,\n",
    "  \"Motivation\": <0-3>,\n",
    "  \"Sleep\": <0-3>,\n",
    "  \"Appetite\": <0-3>,\n",
    "  \"Cognition\": <0-3>,\n",
    "  \"Psychomotor\": <0-3>,\n",
    "  \"SelfWorth\": <0-3>,\n",
    "  \"Suicidality\": <0-3>,\n",
    "  \"Total\": <0-27>,\n",
    "  \"Confidence\": \"<low|medium|high>\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "JSON_RE = re.compile(r\"\\{.*\\}\", re.DOTALL)\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def read_person_only_text(path: str) -> Tuple[str, str]:\n",
    "    \"\"\"Return (person_only_text, name).\"\"\"\n",
    "    data = json.load(open(path, \"r\", encoding=\"utf-8\"))\n",
    "    name = data.get(\"character\", Path(path).stem)\n",
    "    turns = data.get(\"turns\", [])\n",
    "    # keep only the person's lines\n",
    "    person_lines = []\n",
    "    for t in turns:\n",
    "        sp = t.get(\"speaker\", \"\")\n",
    "        tx = (t.get(\"text\") or \"\").strip()\n",
    "        if not tx:\n",
    "            continue\n",
    "        if sp.lower() != \"friend\":   # everything not 'Friend' is the person\n",
    "            person_lines.append(tx)\n",
    "    text = \"\\n\\n\".join(person_lines)\n",
    "    return text, name\n",
    "\n",
    "def soft_chunks(text: str, max_chars=9000) -> List[str]:\n",
    "    if len(text) <= max_chars:\n",
    "        return [text]\n",
    "    parts, acc, total = [], [], 0\n",
    "    for para in text.split(\"\\n\\n\"):\n",
    "        if total + len(para) + 2 > max_chars and acc:\n",
    "            parts.append(\"\\n\\n\".join(acc))\n",
    "            acc, total = [], 0\n",
    "        acc.append(para); total += len(para) + 2\n",
    "    if acc: parts.append(\"\\n\\n\".join(acc))\n",
    "    return parts\n",
    "\n",
    "def json_from_text(txt: str) -> Optional[dict]:\n",
    "    if not txt: return None\n",
    "    t = txt.strip()\n",
    "    if t.startswith(\"```\"):\n",
    "        t = re.sub(r\"^```(?:json)?\\s*\", \"\", t, flags=re.IGNORECASE)\n",
    "        t = re.sub(r\"\\s*```$\", \"\", t)\n",
    "    m = JSON_RE.search(t)\n",
    "    if not m: return None\n",
    "    try:\n",
    "        return json.loads(m.group(0))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def retry_chat(messages, tag: str) -> Optional[dict]:\n",
    "    \"\"\"Call model and return parsed JSON, with retries & logs.\"\"\"\n",
    "    for attempt in range(1, MAX_RETRIES+1):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=SCORING_MODEL,\n",
    "                temperature=TEMPERATURE,\n",
    "                messages=messages\n",
    "            )\n",
    "            txt = resp.choices[0].message.content\n",
    "            obj = json_from_text(txt)\n",
    "            if obj is not None:\n",
    "                return obj\n",
    "            # log bad payload\n",
    "            with open(os.path.join(LOG_DIR, f\"{tag}_attempt{attempt}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(txt or \"[EMPTY]\")\n",
    "        except Exception as e:\n",
    "            with open(os.path.join(LOG_DIR, f\"{tag}_ERROR_attempt{attempt}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"{type(e).__name__}: {e}\")\n",
    "        time.sleep(1.0 + random.random() * attempt)\n",
    "    return None\n",
    "\n",
    "def frequency_to_num(freq: str) -> int:\n",
    "    \"\"\"Fallback mapping if scoring pass fails.\"\"\"\n",
    "    if not freq: return 0\n",
    "    f = freq.strip().lower()\n",
    "    if \"nearly\" in f: return 3\n",
    "    if \"often\" in f:  return 2\n",
    "    if \"occas\" in f: return 1\n",
    "    return 0\n",
    "\n",
    "def combine_scores(chunk_scores: List[dict], confidences: List[str]) -> Tuple[dict, int, str]:\n",
    "    \"\"\"Confidence-weighted average across chunks, then recompute Total.\"\"\"\n",
    "    weights = []\n",
    "    for c in confidences:\n",
    "        cl = (c or \"\").lower()\n",
    "        weights.append(0.5 if cl==\"low\" else 1.0 if cl==\"medium\" else 1.5 if cl==\"high\" else 0.8)\n",
    "\n",
    "    agg = {k: [] for k in DOMAIN_KEYS}\n",
    "    for sc, w in zip(chunk_scores, weights):\n",
    "        if not sc: continue\n",
    "        for k in DOMAIN_KEYS:\n",
    "            v = sc.get(k, None)\n",
    "            if isinstance(v, (int, float)):\n",
    "                agg[k].append((float(v), w))\n",
    "\n",
    "    final = {}\n",
    "    for k in DOMAIN_KEYS:\n",
    "        vals = agg[k]\n",
    "        if not vals:\n",
    "            final[k] = None\n",
    "            continue\n",
    "        num = sum(v*w for v,w in vals)\n",
    "        den = sum(w for _,w in vals)\n",
    "        final[k] = int(round(num / max(den, 1e-8)))\n",
    "\n",
    "    items = [final[k] for k in DOMAIN_KEYS if final[k] is not None and k != \"Suicidality\"] + \\\n",
    "            ([final[\"Suicidality\"]] if final.get(\"Suicidality\") is not None else [])\n",
    "    total = int(sum(items)) if items else None\n",
    "\n",
    "    # overall confidence: mean of weights → label\n",
    "    mw = sum(weights)/len(weights) if weights else 0.8\n",
    "    overall = \"low\" if mw < 0.8 else \"medium\" if mw < 1.2 else \"high\"\n",
    "\n",
    "    return final, total, overall\n",
    "\n",
    "# =========================\n",
    "# CORE PIPELINE (per file)\n",
    "# =========================\n",
    "def score_file(path: str) -> Tuple[dict, dict]:\n",
    "    \"\"\"\n",
    "    Returns (summary_row, detail_rows_dict)\n",
    "    summary_row: {Name, Mood..Suicidality, Total, Confidence}\n",
    "    detail_rows_dict: {\"Name\":..., \"Chunk\": i, <domain>_present, <domain>_freq, ...}\n",
    "    \"\"\"\n",
    "    person_text, name = read_person_only_text(path)\n",
    "    chunks = soft_chunks(person_text, MAX_CHARS_PER_CHUNK)\n",
    "\n",
    "    domain_bullets = \"\\n\".join([f\"- {k}: {desc}\" for k,desc in DOMAINS])\n",
    "\n",
    "    chunk_scores = []\n",
    "    chunk_conf   = []\n",
    "    detail_rows  = []\n",
    "\n",
    "    for idx, ch in enumerate(chunks, start=1):\n",
    "        # Stage 1: extract evidence\n",
    "        ev_obj = retry_chat(\n",
    "            [\n",
    "                {\"role\":\"system\", \"content\": SYSTEM_SUMMARY},\n",
    "                {\"role\":\"user\",   \"content\": USER_SUMMARY_TEMPLATE.format(domain_bullets=domain_bullets, person_text=ch)}\n",
    "            ],\n",
    "            tag=f\"{Path(path).stem}_chunk{idx}_evidence\"\n",
    "        )\n",
    "\n",
    "        if ev_obj is None:\n",
    "            # make a minimal empty evidence shell\n",
    "            ev_obj = {k: {\"present\": False, \"frequency\": \"none\", \"intensity\": \"none\", \"quotes\": []} for k in DOMAIN_KEYS}\n",
    "\n",
    "        # Stage 2: convert evidence -> numeric scores\n",
    "        sc_obj = retry_chat(\n",
    "            [\n",
    "                {\"role\":\"system\", \"content\": SYSTEM_SCORE},\n",
    "                {\"role\":\"user\",   \"content\": USER_SCORE_TEMPLATE.format(evidence_json=json.dumps(ev_obj, ensure_ascii=False))}\n",
    "            ],\n",
    "            tag=f\"{Path(path).stem}_chunk{idx}_score\"\n",
    "        )\n",
    "\n",
    "        # Fallback if stage 2 failed: compute quick scores from frequency only\n",
    "        if sc_obj is None:\n",
    "            sc_obj = {}\n",
    "            for k in DOMAIN_KEYS:\n",
    "                freq = (ev_obj.get(k, {}) or {}).get(\"frequency\", \"none\")\n",
    "                sc_obj[k] = frequency_to_num(freq)\n",
    "            sc_obj[\"Total\"] = int(sum(sc_obj[k] for k in DOMAIN_KEYS))\n",
    "            sc_obj[\"Confidence\"] = \"low\"\n",
    "\n",
    "        # keep per-chunk for aggregation\n",
    "        chunk_scores.append({k: sc_obj.get(k) for k in DOMAIN_KEYS})\n",
    "        chunk_conf.append(sc_obj.get(\"Confidence\",\"medium\"))\n",
    "\n",
    "        # detail row (evidence preview)\n",
    "        for k in DOMAIN_KEYS:\n",
    "            ev = ev_obj.get(k, {}) or {}\n",
    "            detail_rows.append({\n",
    "                \"Name\": name, \"Chunk\": idx, \"Domain\": k,\n",
    "                \"Present\": ev.get(\"present\"),\n",
    "                \"Frequency\": ev.get(\"frequency\"),\n",
    "                \"Intensity\": ev.get(\"intensity\"),\n",
    "                \"Quotes\": \" | \".join((ev.get(\"quotes\") or [])[:3]),\n",
    "                \"Score\": sc_obj.get(k)\n",
    "            })\n",
    "\n",
    "    # Aggregate across chunks\n",
    "    final_items, final_total, final_conf = combine_scores(chunk_scores, chunk_conf)\n",
    "\n",
    "    summary = {\"Name\": name, **final_items, \"Total\": final_total, \"Confidence\": final_conf}\n",
    "    return summary, detail_rows\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "def main():\n",
    "    files = [f for f in os.listdir(INPUT_FOLDER) if f.lower().endswith(\".json\")]\n",
    "    files.sort()\n",
    "\n",
    "    summaries = []\n",
    "    all_details = []\n",
    "\n",
    "    for i, fname in enumerate(files, start=1):\n",
    "        path = os.path.join(INPUT_FOLDER, fname)\n",
    "        try:\n",
    "            summary, details = score_file(path)\n",
    "            summaries.append(summary)\n",
    "            all_details.extend(details)\n",
    "            print(f\"✓ {summary['Name']}: CDI={summary['Total']} ({summary['Confidence']})\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ {fname}: {type(e).__name__}: {e}\")\n",
    "\n",
    "    if summaries:\n",
    "        # write summary\n",
    "        fieldnames = [\"Name\"] + DOMAIN_KEYS + [\"Total\",\"Confidence\"]\n",
    "        with open(OUT_SUMMARY, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "            w.writeheader(); w.writerows(summaries)\n",
    "        print(f\"✅ Saved summary → {OUT_SUMMARY}\")\n",
    "\n",
    "    if all_details:\n",
    "        # write evidence detail\n",
    "        det_fields = [\"Name\",\"Chunk\",\"Domain\",\"Present\",\"Frequency\",\"Intensity\",\"Quotes\",\"Score\"]\n",
    "        with open(OUT_DETAIL, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "            w = csv.DictWriter(f, fieldnames=det_fields)\n",
    "            w.writeheader(); w.writerows(all_details)\n",
    "        print(f\"✅ Saved evidence → {OUT_DETAIL}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
